\section{Описание практической части}
\label{sec:Chapter4} \index{Chapter4}

В данном разделе работы приведены обоснования использования тех или иных технологий и инструментов, а также оценена сложность используемых алгоритмов.

Для написания кода в этой работе используются два языка программирования: Python и C++. Весь код, который участвует в экспериментах написан на C++, так как известно преимущество в скорости этого языка, по сравнению с Python. Фрагменты программы для обучения структур распараллеливались с помощью технологии OpenMP. Как было сказано с предыдущем разделе, для обработки изображений была выбрана библиотека языка Python facerecognition. В связи с этим все скрипты подготовки набора данных были написаны на Python. 

Теперь рассмотрим более подробно каждый метод из предыдущего раздела и опишем используемые для него алгоритмы и структуры данных. Будем полагать, что база данных состоит из $N$ векторов. Вектор $y$ — произвольный вектор из набора данных, вектор $x$ — вектор запроса на поиск.

\subsection{Индексная структура}

Для обучения индексной структуры используется классический алгоритм кластеризации $K$-средних. Основная идея этого алгоритма заключается в том, что данные произвольно разбиваются на кластеры, после чего для каждого из них итеративно перевычисляется новый центр масс, затем векторы снова разбиваются на кластеры в соответствии с тем, какой из новых центров оказался ближе. Временная сложность работы алгоритма $K$-средних имеет следующую оценку: 
\begin{equation}\label{eq:kmeans}
O(IKND),
\end{equation}
где $I$ — число итераций обучения, $K$ — размер разбиения, $N$ — размер базы данных, $D$ — размерность векторов. Параметры $D$ и $N$ обсуждались ранее. Что касается параметра $I$, он был подобран опытным путем. На каждой итерации выводилась общая ошибка кластеризации $E$, и когда $\Delta E$ становилось достаточно мало, фиксировалось текущее значение $I$. Параметр $K$ находится путем оптимизации функции (\ref{eq:index}). Учитывая объем нашей задачи, получаем огромные затраты по времени на обучение алгоритма. Для ускорения этого этапа используется технология параллельного программирования OpenMP.

Поиск по данной структуре можно описать следующей последовательностью действий:
\begin{enumerate}
\item Вычисление расстояний от вектора запроса $x$ до векторов из списка центроидов. Сложность этого этапа оценивается как $O(KD)$;
\item Формирование списка кандидатов для завершающего поиска. Данный список формируется путем добавления в него векторов из ближайшего и смежных с ним кластеров. Причем кластеры выбираются в порядке наименьшего расстояния до запроса. Этот этап требует сортировки $K$ элементов;
\item Вычисление расстояний от $x$ до каждого вектора-кандидата. В зависимости от длины списка кандидатов, изменяется временная сложность вычислений. Гарантируется, что длина списка кандидатов не превышает заданного фиксированного значения;
\item Cортировка списка кандидатов по расстоянию до $x$.
\end{enumerate}

\subsection{Иерархическая структура}

Обучение иерархической и индексной структур в целом схожи. Однако первая проходит два цикла алгоритма $K$-средних. Связано это с тем, что помимо первого разбиения на кластеры, каждая ячейка разбивается повторно тем же алгоритмом. Суммарная сложность обучения оценивается как две сложности (\ref{eq:kmeans}) с параметрами $K_1$ и $K_2$ , которые являются решением задачи оптимизации функции (\ref{eq:hierachicalindex}). Во втором цикле обучения участвует в среднем $\frac{N}{K_1}$ векторов. Для ускорения обучения так же используется технология OpenMP. 

Приближенный поиск ближайших соседей в данной структуре включает следующие этапы:
\begin{enumerate}
\item Поиск ближайшего к вектору $x$ центроида в списке центроидов первичного разбиения. Сложность этого этапа оценивается как $O(K_1D)$;
\item Вычисление расстояний от вектора запроса x до векторов из списка вторичных центроидов, соответствующих первичному центроиду. Сложность этого этапа оценивается как $O(K_2D)$;
\item Формирование списка кандидатов для завершающего поиска. Данный список формируется из ячеек вторичного разбиения и, так же как и в индексной структуре, требует сортировки $K_2$ элементов;
\item Вычисление расстояний от $x$ до каждого вектора-кандидата. Сложность аналогична предыдущей структуре;
\item Cортировка списка кандидатов по расстоянию до $x$.
\end{enumerate}

\subsection{Мульти-индексная структура}

Для обучения мульти-индексной структуры так же применяется алгоритм $K$-средних. Однако теперь обучение проходит на векторах размерности $\frac{D}{2}$. В связи с этим общая сложность обучения может быть представлена как $2 * O(IKN\frac{D}{2})$. В данном случае K является аргументом минимизации функции (\ref{eq:multiindex}). Еще одна особенность обучения состоит в том, что после этого этапа на выходе формируется два независимых списка центроидов. И снова независимые по данным циклы распределяются по нескольким потокам.

Поиск по данной структуре описывается следующей последовательностью действий:
\begin{enumerate}
\item Вычисление расстояний от первой половины вектора $x$ до векторов из первого списка центроидов. Сложность $O(K\frac{D}{2})$;
\item Вычисление расстояний от второй половины вектора x до векторов из второго списка центроидов. Сложность $O(K\frac{D}{2})$;
\item Формирование приоритетной очереди ячеек кандидатов. Данный этап сортирует списки расстояний из пунктов 1. и 2. Затем декартово произведение ячеек первого и второго разбиения добавляются в приоритетную очередь, где в качестве приоритета выступает сумма расстояний до запроса $x$;
\item Формирование списка кандидатов. Из приоритетной очереди выбираются элементы максимального приоритета, и соответствующие им вектора добавляются в список кандидатов;
\item Cортировка списка кандидатов по расстоянию до $x$.
\end{enumerate}